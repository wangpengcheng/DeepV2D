

# 尺寸缩放+fast+2层沙漏网络递归+40000迭代步长
sc-inv, a10, a1, a2, a3, rmse, log_rmse, rel, sq_rel1, sq_rel2, log10, 
0.0900,0.9811,     0.9844,     0.9882,     0.9898,     0.1158,     0.0903,     0.0214,     0.0152,     0.0238,     0.0070,
0.2981,0.5762,     0.7173,     0.7851,     0.8636,     0.5124,     0.3344,     0.2761,     0.2434,     0.2468,     0.0899,
0.3070,0.6230,     0.6944,     0.7595,     0.8424,     0.5431,     0.3534,     0.2948,     0.2767,     0.2819,     0.0934,
单帧处理时间 0.025656700134277344 ms


[stage=2, 38800] loss: 0.024921896
[stage=2, 38900] loss: 0.024963490
[stage=2, 39000] loss: 0.024508086
[stage=2, 39100] loss: 0.024538921
[stage=2, 39200] loss: 0.025280902
[stage=2, 39300] loss: 0.024285481
[stage=2, 39400] loss: 0.024403310
[stage=2, 39500] loss: 0.025344418
[stage=2, 39600] loss: 0.024137927
[stage=2, 39700] loss: 0.025372589
[stage=2, 39800] loss: 0.024264841
[stage=2, 39900] loss: 0.024786476



# molible 
loss 0.035

sc-inv, a10, a1, a2, a3, rmse, log_rmse, rel, sq_rel1, sq_rel2, log10, 
0.2981,0.5762,0.7173,0.7851,0.8636,0.5124,0.3344,     0.2761,     0.2434,     0.2468,     0.0899,

处理时长:
0.38


2021-02-08 18:22:24.154980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
[stage=2,   100] loss: 0.870698324
[stage=2,   200] loss: 0.278681766
[stage=2,   300] loss: 0.212328424
[stage=2,   400] loss: 0.193610742
[stage=2,   500] loss: 0.163854433
[stage=2,   600] loss: 0.167484757
[stage=2,   700] loss: 0.150005543
[stage=2,   800] loss: 0.142340063
[stage=2,   900] loss: 0.127273803
[stage=2,  1000] loss: 0.128090183
[stage=2,  1100] loss: 0.120468385
[stage=2,  1200] loss: 0.115119815
[stage=2,  1300] loss: 0.106226591
[stage=2,  1400] loss: 0.109299256
[stage=2,  1500] loss: 0.099062484
[stage=2,  1600] loss: 0.099547900
[stage=2,  1700] loss: 0.098269491
[stage=2,  1800] loss: 0.093012106
[stage=2,  1900] loss: 0.088795761
[stage=2,  2000] loss: 0.089235692
[stage=2,  2100] loss: 0.083081102
[stage=2,  2200] loss: 0.085830178
[stage=2,  2300] loss: 0.085439604
[stage=2,  2400] loss: 0.082909350
[stage=2,  2500] loss: 0.080252112
[stage=2,  2600] loss: 0.080991268
[stage=2,  2700] loss: 0.078824043
[stage=2,  2800] loss: 0.081253806
[stage=2,  2900] loss: 0.076483033
[stage=2,  3000] loss: 0.078624670
[stage=2,  3100] loss: 0.075250710
[stage=2,  3200] loss: 0.071488448
[stage=2,  3300] loss: 0.074093273
[stage=2,  3400] loss: 0.072364145
[stage=2,  3500] loss: 0.068015362
[stage=2,  3600] loss: 0.072173180
[stage=2,  3700] loss: 0.072305708
[stage=2,  3800] loss: 0.071512729
[stage=2,  3900] loss: 0.071858313
[stage=2,  4000] loss: 0.070490836
[stage=2,  4100] loss: 0.066975040
[stage=2,  4200] loss: 0.065389452
[stage=2,  4300] loss: 0.066101597
[stage=2,  4400] loss: 0.066165975
[stage=2,  4500] loss: 0.065645462
[stage=2,  4600] loss: 0.067076836
[stage=2,  4700] loss: 0.064765492
[stage=2,  4800] loss: 0.066341343
[stage=2,  4900] loss: 0.062238229
[stage=2,  5000] loss: 0.062112286
[stage=2,  5100] loss: 0.060315233
[stage=2,  5200] loss: 0.060608946
[stage=2,  5300] loss: 0.059664551
[stage=2,  5400] loss: 0.059532973
[stage=2,  5500] loss: 0.059261202
[stage=2,  5600] loss: 0.058403442
[stage=2,  5700] loss: 0.058585812
[stage=2,  5800] loss: 0.058415973
[stage=2,  5900] loss: 0.059151587
[stage=2,  6000] loss: 0.054835729
[stage=2,  6100] loss: 0.057548985
[stage=2,  6200] loss: 0.055854734
[stage=2,  6300] loss: 0.058637120
[stage=2,  6400] loss: 0.055308391
[stage=2,  6500] loss: 0.054878416
[stage=2,  6600] loss: 0.056272317
[stage=2,  6700] loss: 0.053666884
[stage=2,  6800] loss: 0.054419951
[stage=2,  6900] loss: 0.054111161
[stage=2,  7000] loss: 0.054326945
[stage=2,  7100] loss: 0.055096244
[stage=2,  7200] loss: 0.052485253
[stage=2,  7300] loss: 0.053976654
[stage=2,  7400] loss: 0.052227510
[stage=2,  7500] loss: 0.052800995
[stage=2,  7600] loss: 0.052305346
[stage=2,  7700] loss: 0.056278117
[stage=2,  7800] loss: 0.052007127
[stage=2,  7900] loss: 0.050405769
[stage=2,  8000] loss: 0.050630975
[stage=2,  8100] loss: 0.050513648
[stage=2,  8200] loss: 0.051535786
[stage=2,  8300] loss: 0.048308256
[stage=2,  8400] loss: 0.049967059
[stage=2,  8500] loss: 0.049569668
[stage=2,  8600] loss: 0.048572640
[stage=2,  8700] loss: 0.048574965
[stage=2,  8800] loss: 0.048808440
[stage=2,  8900] loss: 0.049340335
[stage=2,  9000] loss: 0.047347868
[stage=2,  9100] loss: 0.049065913
[stage=2,  9200] loss: 0.048557230
[stage=2,  9300] loss: 0.050197474
[stage=2,  9400] loss: 0.047159738
[stage=2,  9500] loss: 0.046828502
[stage=2,  9600] loss: 0.046476180
[stage=2,  9700] loss: 0.046233777
[stage=2,  9800] loss: 0.047489238
[stage=2,  9900] loss: 0.045150478
[stage=2, 10000] loss: 0.046128653
[stage=2, 10100] loss: 0.046784003
[stage=2, 10200] loss: 0.046199276
[stage=2, 10300] loss: 0.045688411
[stage=2, 10400] loss: 0.044008162
[stage=2, 10500] loss: 0.044728714
[stage=2, 10600] loss: 0.044460862
[stage=2, 10700] loss: 0.044621787
[stage=2, 10800] loss: 0.043874301
[stage=2, 10900] loss: 0.044317359
[stage=2, 11000] loss: 0.042811608
[stage=2, 11100] loss: 0.043360097
[stage=2, 11200] loss: 0.044458049
[stage=2, 11300] loss: 0.044405660
[stage=2, 11400] loss: 0.043720082
[stage=2, 11500] loss: 0.042452420
[stage=2, 11600] loss: 0.044476247
[stage=2, 11700] loss: 0.041503030
[stage=2, 11800] loss: 0.043742055
[stage=2, 11900] loss: 0.042436744
[stage=2, 12000] loss: 0.043228767
[stage=2, 12100] loss: 0.044000533
[stage=2, 12200] loss: 0.044881403
[stage=2, 12300] loss: 0.041324706
[stage=2, 12400] loss: 0.042489324
[stage=2, 12500] loss: 0.041506157
[stage=2, 12600] loss: 0.043136746
[stage=2, 12700] loss: 0.039721011
[stage=2, 12800] loss: 0.041400372
[stage=2, 12900] loss: 0.041166099
[stage=2, 13000] loss: 0.041620388
[stage=2, 13100] loss: 0.040246734
[stage=2, 13200] loss: 0.042075597
[stage=2, 13300] loss: 0.040372963
[stage=2, 13400] loss: 0.040769301
[stage=2, 13500] loss: 0.041686249
[stage=2, 13600] loss: 0.040782904
[stage=2, 13700] loss: 0.039500226
[stage=2, 13800] loss: 0.041148624
[stage=2, 13900] loss: 0.042256935
[stage=2, 14000] loss: 0.040138263
[stage=2, 14100] loss: 0.040584024
[stage=2, 14200] loss: 0.039493700
[stage=2, 14300] loss: 0.040129710
[stage=2, 14400] loss: 0.038381801
[stage=2, 14500] loss: 0.039675385
[stage=2, 14600] loss: 0.040230723
[stage=2, 14700] loss: 0.039680481
[stage=2, 14800] loss: 0.037828255
[stage=2, 14900] loss: 0.039346111
[stage=2, 15000] loss: 0.040648800
[stage=2, 15100] loss: 0.037689345
[stage=2, 15200] loss: 0.039108106
[stage=2, 15300] loss: 0.038146662
[stage=2, 15400] loss: 0.040840785
[stage=2, 15500] loss: 0.038368091
[stage=2, 15600] loss: 0.039931861
[stage=2, 15700] loss: 0.038325385
[stage=2, 15800] loss: 0.037546003
[stage=2, 15900] loss: 0.038410622
[stage=2, 16000] loss: 0.038003400
[stage=2, 16100] loss: 0.034748153
[stage=2, 16200] loss: 0.032701684
[stage=2, 16300] loss: 0.032332459
[stage=2, 16400] loss: 0.032413417
[stage=2, 16500] loss: 0.031760196
[stage=2, 16600] loss: 0.032528771
[stage=2, 16700] loss: 0.031577191
[stage=2, 16800] loss: 0.030854716
[stage=2, 16900] loss: 0.031123693
[stage=2, 17000] loss: 0.031399984
[stage=2, 17100] loss: 0.032399717
[stage=2, 17200] loss: 0.030827055
[stage=2, 17300] loss: 0.031536155
[stage=2, 17400] loss: 0.030859927
[stage=2, 17500] loss: 0.031278259
[stage=2, 17600] loss: 0.031255778
[stage=2, 17700] loss: 0.031342752
[stage=2, 17800] loss: 0.030481302
[stage=2, 17900] loss: 0.031204959
[stage=2, 18000] loss: 0.030781539
[stage=2, 18100] loss: 0.030686454
[stage=2, 18200] loss: 0.032199450
[stage=2, 18300] loss: 0.029796402
[stage=2, 18400] loss: 0.030477698
[stage=2, 18500] loss: 0.030770397
[stage=2, 18600] loss: 0.030683142
[stage=2, 18700] loss: 0.030714469
[stage=2, 18800] loss: 0.030674805
[stage=2, 18900] loss: 0.030328643
[stage=2, 19000] loss: 0.030922395
[stage=2, 19100] loss: 0.030075908
[stage=2, 19200] loss: 0.030677921
[stage=2, 19300] loss: 0.030375732
[stage=2, 19400] loss: 0.030490543
[stage=2, 19500] loss: 0.031058110
[stage=2, 19600] loss: 0.031220328
[stage=2, 19700] loss: 0.029262417
[stage=2, 19800] loss: 0.030942549
[stage=2, 19900] loss: 0.030269140

time cost 0.040457963943481445 ms
sc-inv, a10, a1, a2, a3, rmse, log_rmse, rel, sq_rel1, sq_rel2, log10, 
0.3070,     0.6230,     0.6944,     0.7595,     0.8424,     0.5431,     0.3534,     0.2948,     0.2767,     0.2819,     0.0934,


[stage=2,   100] loss: 0.982995857
[stage=2,   200] loss: 0.302617980
[stage=2,   300] loss: 0.205721539
[stage=2,   400] loss: 0.172174523
[stage=2,   500] loss: 0.146022314
[stage=2,   600] loss: 0.145721279
[stage=2,   700] loss: 0.132133851
[stage=2,   800] loss: 0.131733466
[stage=2,   900] loss: 0.117880918
[stage=2,  1000] loss: 0.124340704
[stage=2,  1100] loss: 0.109853805
[stage=2,  1200] loss: 0.115496216
[stage=2,  1300] loss: 0.106276763
[stage=2,  1400] loss: 0.110269595
[stage=2,  1500] loss: 0.100515760
[stage=2,  1600] loss: 0.104405862
[stage=2,  1700] loss: 0.103001542
[stage=2,  1800] loss: 0.098835095
[stage=2,  1900] loss: 0.099605683
[stage=2,  2000] loss: 0.097840837
[stage=2,  2100] loss: 0.094030835
[stage=2,  2200] loss: 0.095219288
[stage=2,  2300] loss: 0.094219339
[stage=2,  2400] loss: 0.095815309
[stage=2,  2500] loss: 0.092424922
[stage=2,  2600] loss: 0.092824166
[stage=2,  2700] loss: 0.093633560
[stage=2,  2800] loss: 0.091429653
[stage=2,  2900] loss: 0.091136700
[stage=2,  3000] loss: 0.089103240
[stage=2,  3100] loss: 0.092861564
[stage=2,  3200] loss: 0.088112298
[stage=2,  3300] loss: 0.090161593
[stage=2,  3400] loss: 0.086594512
[stage=2,  3500] loss: 0.086507136
[stage=2,  3600] loss: 0.087681497
[stage=2,  3700] loss: 0.087338313
[stage=2,  3800] loss: 0.085665126
[stage=2,  3900] loss: 0.085944647
[stage=2,  4000] loss: 0.088837733
[stage=2,  4100] loss: 0.085247471
[stage=2,  4200] loss: 0.083333237
[stage=2,  4300] loss: 0.082685994
[stage=2,  4400] loss: 0.085038328
[stage=2,  4500] loss: 0.084601962
[stage=2,  4600] loss: 0.082509286
[stage=2,  4700] loss: 0.084544835
[stage=2,  4800] loss: 0.084099880
[stage=2,  4900] loss: 0.079667637
[stage=2,  5000] loss: 0.079562059
[stage=2,  5100] loss: 0.080737969
[stage=2,  5200] loss: 0.080012735
[stage=2,  5300] loss: 0.078233538
[stage=2,  5400] loss: 0.079721669
[stage=2,  5500] loss: 0.077810265
[stage=2,  5600] loss: 0.079550338
[stage=2,  5700] loss: 0.077363564
[stage=2,  5800] loss: 0.074390125
[stage=2,  5900] loss: 0.080113873
[stage=2,  6000] loss: 0.070479616
[stage=2,  6100] loss: 0.078365019
[stage=2,  6200] loss: 0.073124380
[stage=2,  6300] loss: 0.074416621
[stage=2,  6400] loss: 0.072452891
[stage=2,  6500] loss: 0.074358005
[stage=2,  6600] loss: 0.071898381
[stage=2,  6700] loss: 0.073915719
[stage=2,  6800] loss: 0.070918269
[stage=2,  6900] loss: 0.073140872
[stage=2,  7000] loss: 0.070657461
[stage=2,  7100] loss: 0.071783394
[stage=2,  7200] loss: 0.071517561
[stage=2,  7300] loss: 0.075385632
[stage=2,  7400] loss: 0.070753263
[stage=2,  7500] loss: 0.071047916
[stage=2,  7600] loss: 0.072070766
[stage=2,  7700] loss: 0.073021600
[stage=2,  7800] loss: 0.068434160
[stage=2,  7900] loss: 0.069947487
[stage=2,  8000] loss: 0.070389294
[stage=2,  8100] loss: 0.066676185
[stage=2,  8200] loss: 0.070704531
[stage=2,  8300] loss: 0.067987287
[stage=2,  8400] loss: 0.070153556
[stage=2,  8500] loss: 0.068082264
[stage=2,  8600] loss: 0.064732446
[stage=2,  8700] loss: 0.067249281
[stage=2,  8800] loss: 0.068635514
[stage=2,  8900] loss: 0.065976051
[stage=2,  9000] loss: 0.064811162
[stage=2,  9100] loss: 0.065139263
[stage=2,  9200] loss: 0.066726500
[stage=2,  9300] loss: 0.064951057
[stage=2,  9400] loss: 0.063196358
[stage=2,  9500] loss: 0.063186523
[stage=2,  9600] loss: 0.065153672
[stage=2,  9700] loss: 0.064126760
[stage=2,  9800] loss: 0.064867625
[stage=2,  9900] loss: 0.060766715
[stage=2, 10000] loss: 0.065485774
WARNING:tensorflow:From /home/node/.conda/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
[stage=2, 10100] loss: 0.061688098
[stage=2, 10200] loss: 0.063556355
[stage=2, 10300] loss: 0.063141143
[stage=2, 10400] loss: 0.062654210
[stage=2, 10500] loss: 0.063396280
[stage=2, 10600] loss: 0.061702987
[stage=2, 10700] loss: 0.062570513
[stage=2, 10800] loss: 0.059362600
[stage=2, 10900] loss: 0.059786258
[stage=2, 11000] loss: 0.060415514
[stage=2, 11100] loss: 0.061108831
[stage=2, 11200] loss: 0.063742448
[stage=2, 11300] loss: 0.059612582
[stage=2, 11400] loss: 0.061370658
[stage=2, 11500] loss: 0.059456750
[stage=2, 11600] loss: 0.059320015
[stage=2, 11700] loss: 0.056547920
[stage=2, 11800] loss: 0.060011449
[stage=2, 11900] loss: 0.058314019
[stage=2, 12000] loss: 0.060151619
[stage=2, 12100] loss: 0.061094449
[stage=2, 12200] loss: 0.060479179
[stage=2, 12300] loss: 0.055721042
[stage=2, 12400] loss: 0.059037939
[stage=2, 12500] loss: 0.057623522
[stage=2, 12600] loss: 0.059141514
[stage=2, 12700] loss: 0.054257762
[stage=2, 12800] loss: 0.057456005
[stage=2, 12900] loss: 0.056177151
[stage=2, 13000] loss: 0.058215332
[stage=2, 13100] loss: 0.056061517
[stage=2, 13200] loss: 0.055587501
[stage=2, 13300] loss: 0.056602229
[stage=2, 13400] loss: 0.057026058
[stage=2, 13500] loss: 0.055486147
[stage=2, 13600] loss: 0.055805834
[stage=2, 13700] loss: 0.053756215
[stage=2, 13800] loss: 0.058374979
[stage=2, 13900] loss: 0.055366026
[stage=2, 14000] loss: 0.054360392
[stage=2, 14100] loss: 0.054538899
[stage=2, 14200] loss: 0.053479712
[stage=2, 14300] loss: 0.055648120
[stage=2, 14400] loss: 0.052363764
[stage=2, 14500] loss: 0.056389102
[stage=2, 14600] loss: 0.054693204
[stage=2, 14700] loss: 0.053726528
[stage=2, 14800] loss: 0.051669895
[stage=2, 14900] loss: 0.053277372
[stage=2, 15000] loss: 0.054156820
[stage=2, 15100] loss: 0.052348255
[stage=2, 15200] loss: 0.053371915
[stage=2, 15300] loss: 0.052158015
[stage=2, 15400] loss: 0.055005921
[stage=2, 15500] loss: 0.050870008
[stage=2, 15600] loss: 0.052335217
[stage=2, 15700] loss: 0.052594428
[stage=2, 15800] loss: 0.050884886
[stage=2, 15900] loss: 0.051617437
[stage=2, 16000] loss: 0.051801273
[stage=2, 16100] loss: 0.052637823
[stage=2, 16200] loss: 0.050877296
[stage=2, 16300] loss: 0.050327857
[stage=2, 16400] loss: 0.050487236
[stage=2, 16500] loss: 0.050235664
[stage=2, 16600] loss: 0.050952439
[stage=2, 16700] loss: 0.049781775
[stage=2, 16800] loss: 0.049488810
[stage=2, 16900] loss: 0.049932478
[stage=2, 17000] loss: 0.049347991
[stage=2, 17100] loss: 0.050068681
[stage=2, 17200] loss: 0.048684083
[stage=2, 17300] loss: 0.050344066
[stage=2, 17400] loss: 0.049213154
[stage=2, 17500] loss: 0.048990919
[stage=2, 17600] loss: 0.048590556
[stage=2, 17700] loss: 0.049350382
[stage=2, 17800] loss: 0.047270352
[stage=2, 17900] loss: 0.048444334
[stage=2, 18000] loss: 0.048632906
[stage=2, 18100] loss: 0.047619715
[stage=2, 18200] loss: 0.049659526
[stage=2, 18300] loss: 0.046624785
[stage=2, 18400] loss: 0.048367301
[stage=2, 18500] loss: 0.048271888
[stage=2, 18600] loss: 0.048893245
[stage=2, 18700] loss: 0.048426749
[stage=2, 18800] loss: 0.049485213
[stage=2, 18900] loss: 0.049675804
[stage=2, 19000] loss: 0.047953179
[stage=2, 19100] loss: 0.046931902
[stage=2, 19200] loss: 0.048246755
[stage=2, 19300] loss: 0.047812806
[stage=2, 19400] loss: 0.047952793
[stage=2, 19500] loss: 0.047241327
[stage=2, 19600] loss: 0.047794844
[stage=2, 19700] loss: 0.045980709
[stage=2, 19800] loss: 0.047367099
[stage=2, 19900] loss: 0.046258582
[stage=2, 20000] loss: 0.047090292
[stage=2, 20100] loss: 0.043269561
[stage=2, 20200] loss: 0.042306225
[stage=2, 20300] loss: 0.039591118
[stage=2, 20400] loss: 0.040452812
[stage=2, 20500] loss: 0.040121289
[stage=2, 20600] loss: 0.040654246
[stage=2, 20700] loss: 0.040655979
[stage=2, 20800] loss: 0.038934200
[stage=2, 20900] loss: 0.038824022
[stage=2, 21000] loss: 0.039604704
[stage=2, 21100] loss: 0.039516881
[stage=2, 21200] loss: 0.038795314
[stage=2, 21300] loss: 0.039233180
[stage=2, 21400] loss: 0.037952782
[stage=2, 21500] loss: 0.038982273
[stage=2, 21600] loss: 0.038678705
[stage=2, 21700] loss: 0.038005164
[stage=2, 21800] loss: 0.038496024
[stage=2, 21900] loss: 0.038955599
[stage=2, 22000] loss: 0.038175691
[stage=2, 22100] loss: 0.039933204
[stage=2, 22200] loss: 0.037705396
[stage=2, 22300] loss: 0.038701222
[stage=2, 22400] loss: 0.038195931
[stage=2, 22500] loss: 0.039003047
[stage=2, 22600] loss: 0.038013565
[stage=2, 22700] loss: 0.039238389
[stage=2, 22800] loss: 0.037917380
[stage=2, 22900] loss: 0.037993323
[stage=2, 23000] loss: 0.038397339
[stage=2, 23100] loss: 0.038966547
[stage=2, 23200] loss: 0.036927782
[stage=2, 23300] loss: 0.038841409
[stage=2, 23400] loss: 0.039240115
[stage=2, 23500] loss: 0.036798864
[stage=2, 23600] loss: 0.039128265
[stage=2, 23700] loss: 0.037282108
[stage=2, 23800] loss: 0.037825042
[stage=2, 23900] loss: 0.037242408
[stage=2, 24000] loss: 0.038215616
[stage=2, 24100] loss: 0.037521733
[stage=2, 24200] loss: 0.038805876
[stage=2, 24300] loss: 0.037411105
[stage=2, 24400] loss: 0.037935291
[stage=2, 24500] loss: 0.037447646
[stage=2, 24600] loss: 0.039868525
[stage=2, 24700] loss: 0.036218294
[stage=2, 24800] loss: 0.038002214
[stage=2, 24900] loss: 0.037601361




